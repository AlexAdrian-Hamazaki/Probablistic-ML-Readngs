{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Inference is the act of turning sample data into generalizations, usually with a calculated degree of uncertainty\n",
    "\n",
    "The term Baysian refers to inference methods that model the degree of uncertainty using Baye's rule to update the degree of uncertainty given the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Rule\n",
    "\n",
    "Computees the pdf over possible values of an unknown quantity H given some observed data Y=y\n",
    "\n",
    "\n",
    "$\\rho(H=h | Y=y) = \\frac{\\rho(H=h)\\rho(Y=y | H=h)}{\\rho (Y=y)}$\n",
    "\n",
    "Which follows from the identity\n",
    "\n",
    "$\\rho(h,y) = \\rho(h|y)\\rho(y) = \\rho(y|h)\\rho(h)$\n",
    "\n",
    "### Prior Distribution\n",
    "\n",
    "In Bayes rule, $\\rho(H)$ is called the prior distribution\n",
    "\n",
    "It represents what we know about the possible values of H before we see any data (Y).\n",
    "\n",
    "### Observed Distribution\n",
    "\n",
    "$\\rho(Y | H=h)$ is called the observed distribution.\n",
    "\n",
    "The observed distribution represents the possible values of Y we expect to see if H=h.\n",
    "\n",
    "### Likelyhood  Function\n",
    "\n",
    "When we evaluate the observation distribution at a point Y=y, we get...\n",
    "\n",
    "$\\rho(Y=y | H=h)$, which is the likelyhood function for a given value y at h\n",
    "\n",
    "### Unormalized Joint Distribution\n",
    "\n",
    "Multiplying the prior distribution by the likehoood function for each H gives the unnormalized joint distribution\n",
    "\n",
    "$\\rho(H=h, Y=y) = \\rho(H =h)\\rho(Y=y|H=h)$\n",
    "\n",
    "### Marginal Likelyhood\n",
    "\n",
    "Dividing by the marginal dist for each y in the joint gives us normalized joint pdf\n",
    "\n",
    "This gives us bayes rule\n",
    "\n",
    "$\\rho(Y=y) is given by computing the conditional probability marginals across H\n",
    "\n",
    "$\\rho(Y=y) = \\sum_{h \\in \\chi} \\rho(H = h) p(Y =y | H = h) $\n",
    "\n",
    "Note. All we are doing here is calculating the conditional probability of each value of H (in the state space), aka each marginal of H given Y=y.\n",
    "This gives us the total possible probability across H, which we use to normalize \n",
    "\n",
    "### Posterior Distribution\n",
    "\n",
    "After normalizing by the marginal likelyhood, we have aa new pdf which is called the poseterior distribution which\n",
    "\n",
    "represents our new pdf, for the information we have (Y).\n",
    "\n",
    "$\\rho(H =h | Y=y)$\n",
    "\n",
    "### summary\n",
    "\n",
    "Baye's rule can be summarized as follows\n",
    "\n",
    "posterior distribution = prior distribution x likelyhood\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1. Testing for Covid\n",
    "\n",
    "Let H=1 be the event you are infected, and H=0 be not infection\n",
    "\n",
    "Let Y=1 Be positive test and Y=0 be a negative test\n",
    "\n",
    "We want to compute $\\rho(H =h| Y=y), h \\in {0,1}$\n",
    "\n",
    "We can write the distribution of H we want to compute expliccelty\n",
    "\n",
    "$\\rho(H=0|Y=y), \\rho(H=1|Y=y)$. And this can be simplified into being denoted using just the pdf H, and not specifying the state space of y and H\n",
    "\n",
    "\n",
    "$\\rho(H|y)$\n",
    "\n",
    "\n",
    "### Likelyhoods\n",
    "\n",
    "$\\rho(Y=1|H=1)$ = 0.85\n",
    "$\\rho(Y=0|H=1)$ = 0.15\n",
    "$\\rho(Y=0 | H=0)$ = 0.975\n",
    "$\\rho(Y=1 | H=0)$ = 0.025\n",
    "\n",
    "### Prior\n",
    "\n",
    "We typically specify prior\n",
    "\n",
    "We will specify $\\rho(H=1)$, which represents the general prevelance (percent of people) that had covid in new york in spring 2020\n",
    "\n",
    "### Examples\n",
    "\n",
    "If you test positive...\n",
    "\n",
    "$\\rho(H=1 | Y=1) = \\frac{\\rho(Y=1|H=1)\\rho(H=1)}{\\rho(Y=1|H=1)\\rho(H=1) + rho(Y=1|H=0)\\rho(H=0)}$\n",
    "\n",
    "$\\rho(H=1 | Y=1) = \\frac{TPR x prior}{TPR x prior + FPR x (1-prior)}$ \n",
    "\n",
    "= 0.795\n",
    "\n",
    "So You have a 0.795% chance to be infected with a covid if you tested positive\n",
    "\n",
    "This is the posterior probability given our prior knowledge about the situation, and the likelyhood of the outcome\n",
    "\n",
    "\n",
    "Notice that if we modify our prior prevelance to be 0.01, we would only expect a posterior probability of 0.26.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 Monty Hall Problem\n",
    "\n",
    "This is the classic 3 door problem where you want the price and after you pick one, the host provides more information\n",
    "by revealing a door that does not contain the prize\n",
    "\n",
    "Should you switch doors?\n",
    "\n",
    "Let $H_i$ Denote the hypothesis that the prize is behind door $\\text(i)$\n",
    "Let Y = Door host chooses\n",
    "\n",
    "### Prior Distribution\n",
    "\n",
    "We assume a-prioi of any information being given, the probability of the car beinh behind all 3 doors is the same\n",
    "\n",
    "$Pr(H_1)=Pr(H_2)=Pr(H_3)=1/3$\n",
    "\n",
    "### Likelyhood calculations\n",
    "\n",
    "Suppose you choose door 1.\n",
    "\n",
    "If the prize is behind door 1, then the host randomly chooses to open door 2 or 3\n",
    "$P(Y=2|H_1) = 1/2$\n",
    "$P(Y=3|H_1) = 1/2$\n",
    "\n",
    "If prize is not behind door 1, then the host is forced to choose the door the prize is not in\n",
    "\n",
    "If the prize is behind door 3...\n",
    "$P(Y=2|H_3)= 1$\n",
    "$P(Y=3|H_3)= 0$, there is a zero probability the host picks door 3\n",
    "\n",
    "If the prize is behind door 2...\n",
    "$P(Y=2|H_2)= 0$, there is a zero probability the host picks door 2\n",
    "$P(Y=3|H_2)= 1$, host opens door 3\n",
    "\n",
    "\n",
    "### Updating Posterior Distributions after host reveals new info\n",
    "\n",
    "Suppose we choose door 1 (H1)...\n",
    "Suppose host opens door 3 (Y=3)\n",
    "\n",
    "$P(H_i | Y=3) = \\frac{P(Y=3|H_i)P(H_i)}{P(Y=3)}$\n",
    "\n",
    "Hypothesis that car is behind door 1\n",
    "$P(H_1 | Y=3) = \\frac{1/2 * 1/3}{1/2}$ = 1/3\n",
    "\n",
    "Hypothesis that car is behind door 2\n",
    "$P(H_2 | Y=3) = \\frac{1 * 1/3}{1/2}$ = 2/3\n",
    "\n",
    "Hypothesis that car is behind door 3\n",
    "$P(H_3 | Y=3) = \\frac{0 * 1/3}{1/2}$ = 0\n",
    "\n",
    "Here we see that the host's opening of a door gives us additional information, which updates our known posterior distribution\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
